{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and normalizing data using pandas\n",
    "data = pd.read_csv('mnist_train.csv', header = None) # Takes approximately 7-9 seconds in loading\n",
    "data_norm = data/255 # Normalizing the data\n",
    "test_data = pd.read_csv('mnist_test.csv', header = None)\n",
    "test_data_norm = test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating the data\n",
    "train_X = data_norm.drop(0, axis = 1).T # Getting all the images in a single variable\n",
    "# train_X = tf.reshape([-1, 28, 28, 1])\n",
    "tf.reshape?\n",
    "train_Y = data[0].values.reshape(60000, 1) # Getting labels \n",
    "\n",
    "test_X = test_data_norm.drop(0, axis = 1).T # Getting all the test images in a single variable \n",
    "test_Y = test_data[0].values.reshape(10000, 1) # Getting labels\n",
    "train_Y = np_utils.to_categorical(train_Y, 10)\n",
    "test_Y = np_utils.to_categorical(test_Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 60000\n",
      "Number of test examples 10000\n",
      "Shape of trianing set is (784, 60000)\n",
      "Shape of training labels is (60000, 1)\n",
      "Shape of test set is (784, 10000)\n",
      "Shape of test labels is (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Testing the shape of the data\n",
    "print('Number of training examples', train_X.shape[1])\n",
    "print('Number of test examples', test_X.shape[1])\n",
    "print('Shape of trianing set is', train_X.shape)\n",
    "print('Shape of training labels is', train_Y.shape)\n",
    "print('Shape of test set is', test_X.shape)\n",
    "print('Shape of test labels is', test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label for this image is [8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b078c18>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "image_num = 19000\n",
    "a = train_X[image_num].values.reshape(28,28)\n",
    "label = train_Y[image_num]\n",
    "print('The label for this image is', label)\n",
    "plt.imshow(a, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    x = tf.placeholder(tf.float32, shape = (None, n_H0, n_W0, n_C0))\n",
    "    y = tf.placeholder(tf.float32, shape = (None, n_y))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    W1 = tf.get_variable('W1', [4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable('W2', [2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    parameters = {'W1' : W1,\n",
    "                  'W2' : W2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1], padding = 'SAME')\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1, 4, 4, 1], strides = [1, 4, 4, 1], padding = 'SAME')\n",
    "    P = tf.contrib.layers.flatten(P2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P, 6, activation_fn = None)\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels = Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009, num_epoches = 100, minibatch_size = 64, print_cost = True):\n",
    "    ops.reset_default_graph()\n",
    "    seed = 3\n",
    "    (m, n_H, n_W0, n_C0) = X_train.shape\n",
    "    n_y = Y_train.shape[1]\n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sees:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epoches):\n",
    "            minibatch_cost = 0\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y: minibatch_Y})\n",
    "                minibatch_cost += temp_cost/num_minibatches\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print('Cost after epoch %i : %f'%(epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations (per tens)')\n",
    "    plt.title('Learning rate = ', str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    predict_op = tf.argmax(Z3, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    print(accuracy)\n",
    "    train_accuracy = accuracy.eval({X: X_train, Y:Y_train})\n",
    "    test_accuracy = accuracy.eval({X : X_test, Y : Y_test})\n",
    "    print('Train Accuracy:', train_accuracy)\n",
    "    print('Test Accuracy:', test_accuracy)\n",
    "    \n",
    "    return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f016a5638ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-ad62527c338f>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epoches, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_W0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_C0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow website tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute 'main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-58a08c6c06b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute 'main'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
